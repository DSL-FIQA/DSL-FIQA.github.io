<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>DSL-FIQA: Assessing Facial Image Quality via Dual-Set Degradation Learning and Landmark-Guided Transformer</title>
  
  <!-- Analytics & Libraries -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-EDF010G6PN"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-EDF010G6PN');
  </script>
  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script src="https://unpkg.com/interactjs/dist/interact.min.js"></script>

  <!-- Stylesheets -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="./static/slick/slick.css"/>
  <link rel="stylesheet" type="text/css" href="./static/slick/slick-theme.css"/>
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <script defer src="./static/js/fontawesome.all.min.js"></script>
</head>
<body>

<!-- Page Header -->
<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="container has-text-centered">
        <h1 class="title is-1 publication-title">DSL-FIQA: Assessing Facial Image Quality via Dual-Set Degradation Learning and Landmark-Guided Transformer</h1>
        <div class="is-size-5 publication-authors">
          <div class="author-block"><a href="https://sites.google.com/view/weitingchen/home">Wei-Ting Chen</a> <sup>1,2</sup></div>
          <div class="author-block"><a href="https://www.linkedin.com/in/krishnanguru/">Gurunandan Krishnan</a> <sup>2</sup></div>
          <div class="author-block"><a href="https://www.linkedin.com/in/qiang-gao-sd">Qiang Gao</a> <sup>2</sup></div>
          <div class="author-block"><a href="https://homepage.ntu.edu.tw/~sykuo/">Sy-Yen Kuo</a> <sup>1</sup></div>
          <div class="author-block"><a href="https://sizhuoma.netlify.app/">Sizhou Ma</a> <sup>2*</sup></div>
          <div class="author-block"><a href="https://jianwang-cmu.github.io/">Jian Wang</a> <sup>2*</sup></div>
        </div>
        <div class="is-size-5 publication-authors">
          <span class="author-block"><sup>1</sup>National Taiwan University,</span>
          <span class="author-block"><sup>2</sup>Snap Inc.</span>
        </div>
        <div class="is-size-5 publication-authors">
          <span class="author-block"> </sup>* Co-corresponding authors</span>
        </div>
        <div class="is-size-5 publication-authors">
          <span class="author-block"> </sup>(CVPR 2024)</span>
        </div>
        
        <div class="column has-text-centered">
          <div class="publication-links">
            <span class="link-block">
                <a href="https://arxiv.org/abs/1234.56789" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv</span>
                </a>
            </span>
            <span class="link-block">
                <a href="https://github.com/robustsam/RobustSAM" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span><span>Code</span>
                </a>
            </span>
            <span class="link-block">
                <a href="https://github.com/robustsam/RobustSAM/data" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="far fa-images"></i></span><span>Data</span>
                </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Main Content -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
Generic Face Image Quality Assessment (GFIQA) evaluates the perceptual quality of facial images, which is crucial in improving image restoration algorithms and selecting high-quality face images for downstream tasks.
We present a novel transformer-based method for GFIQA, which is aided by two unique mechanisms. First, a novel Dual-Set Degradation Representation Learning (DSL) mechanism uses facial images with both synthetic and real degradations to decouple degradation from content, ensuring generalizability to real-world scenarios. This self-supervised method learns degradation features on a global scale, providing a robust alternative to conventional methods that use local patch information in degradation learning. 
Second, our transformer leverages facial landmarks to emphasize visually salient parts of a face image in evaluating its perceptual quality. We also introduce a balanced and diverse Comprehensive Generic Face IQA (CGFIQA-40k) dataset of 40K images carefully designed to overcome the biases, in particular the imbalances in skin tone and gender representation, in existing datasets.
Extensive analysis and evaluation demonstrate the robustness of our method, marking a significant improvement over prior methods.            
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Architecture Section -->
<div class="container is-max-desktop">
  <div class="content has-text-justified">
    <h2 class="title is-3">Architecture of DSL-FIQA</h2>
    <p>The model contains a core GFIQA network, a degradation extraction network, and a landmark detection network. In our approach, face images are cropped into several patches to fit the input size requirements of the pre-trained ViT feature extractor. Each patch is then processed individually, and their Mean Opinion Scores (MOS) are averaged to determine the final quality score.</p>
    <div class="has-text-centered">
      <img style="width: 100%;" src="./file/overview.png" alt="DCE architecture."/>
    </div>
  </div>
</div>


<!-- DSL Section -->
<div class="container is-max-desktop">
  <div class="content has-text-justified">
    <h2 class="title is-3">Dual-Set Degradation Representation Learning (DSL)</h2>
    <p> On the left, the process of contrastive optimization is
depicted, utilizing two unique image sets. Degradation representations are extracted, followed by soft proximity mapping (SPM) calcula-
tions and contrastive optimization, compelling the degradation encoder to focus on learning specific degradation features. The right side
emphasizes the bidirectional characteristic of our approach, highlighting the comprehensive strategy for identifying and understanding
image degradations through contrastive learning.</p>
    <div class="has-text-centered">
      <img style="width: 100%;" src="./file/DCE_v7.png" alt="DCE architecture."/>
    </div>
  </div>
</div>

  
<!-- Bibliography Section -->
<section class="section" id="BibTeX">
  <div class="container content is-max-desktop">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{chen2024robustsam,
  author = {Chen, Wei-Ting and Krishnan, Gurunandan and Gao, Qiang and Kuo, Sy-Yen and Ma, Sizhou and Wang, Jian},
  title = {DSL-FIQA: Assessing Facial Image Quality via Dual-Set Degradation Learning and Landmark-Guided Transformer},
  journal = {CVPR},
  issue_date = {2024}
}</code></pre>
  </div>
</section>

<!-- Footer -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- Footer content here -->
    </div>
  </div>
</footer>

<script type="text/javascript" src="./static/slick/slick.min.js"></script>
</body>
</html>
